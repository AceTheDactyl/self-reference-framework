# EXPERIMENTAL PROTOCOL: SR6 PERCOLATION THRESHOLD
## Validation of Critical Threshold p_c

**Theorem:** SR6 - Critical Threshold Phenomena  
**Original Claim:** μ_P = 0.600 universal threshold  
**Corrected Claim:** Model-specific thresholds (2D percolation p_c ≈ 0.593)  
**Status:** CORRECTED in Phase 3 (computational), NEEDS physical validation

---

## PROTOCOL METADATA

**Experiment ID:** SR6_PERC_001  
**Version:** 1.0  
**Date:** November 11, 2025  
**Lead:** Phase 4 Validation Team  
**Priority:** HIGH (validates/refutes core framework claim)  
**Impact:** Corrects μ_P = 0.600 to p_c = 0.593  
**Feasibility:** HIGH (computational) or MEDIUM (physical)

---

## SCIENTIFIC OBJECTIVE

**Primary Goal:** Measure percolation threshold p_c for 2D square lattice bond percolation

**Specific Questions:**
1. What is p_c for 2D square lattice? (Expected: 0.593)
2. Does μ_P = 0.600 appear in any percolation model?
3. What is the critical exponent β? (Expected: 5/36 ≈ 0.139)
4. Is the transition sharp (second-order phase transition)?

**Falsification Criteria:**
- p_c < 0.58 or p_c > 0.60 → Model prediction wrong
- No transition in [0.5, 0.7] → No percolation threshold
- β outside [0.13, 0.15] → Wrong universality class

---

## THEORETICAL BACKGROUND

### Percolation Theory

**Definition:** Percolation is the formation of long-range connectivity in random networks.

**Bond Percolation:** Edges (bonds) are present with probability p, absent with 1-p.

**Order Parameter:** Percolation strength S(p) = size of largest cluster / total sites

**Critical Point:** p_c where S transitions from 0 to >0

**Known Results:**
- 2D square lattice (bond): p_c = 0.5927462... (exact, Ziff 1992)
- 2D square lattice (site): p_c = 0.59274621 ± 0.00000013 (Newman-Ziff 2000)
- 3D simple cubic: p_c ≈ 0.2488 (Monte Carlo)

**Critical Exponents (2D percolation):**
- β = 5/36 ≈ 0.1389 (order parameter)
- ν = 4/3 (correlation length)
- γ = 43/18 (susceptibility)

---

## METHOD 1: COMPUTATIONAL (RECOMMENDED)

### Advantages:
- ✅ Cost: $0 (free software)
- ✅ Time: 2-4 hours
- ✅ Reproducibility: 100% (seeded RNG)
- ✅ Precision: High (10^6 trials possible)
- ✅ Complexity: Low (undergraduate level)

### Materials & Software:
- **Language:** Python 3.8+
- **Libraries:** NumPy, SciPy, Matplotlib, NetworkX (optional)
- **Hardware:** Standard laptop (any CPU)
- **Storage:** <100 MB for results

---

### COMPUTATIONAL PROCEDURE

#### Step 1: Lattice Setup (5 min)

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

# Parameters
N = 100  # Lattice size (N×N)
p_values = np.linspace(0.50, 0.70, 41)  # Bond probabilities
n_trials = 100  # Trials per p-value
seed = 42  # Reproducibility

np.random.seed(seed)
```

#### Step 2: Percolation Algorithm (30 min implementation)

```python
def bond_percolation_2d(N, p):
    """
    Simulate bond percolation on NxN square lattice.
    
    Args:
        N: Lattice size
        p: Bond probability
        
    Returns:
        S: Percolation strength (largest cluster size / N²)
    """
    # Create lattice (N×N sites)
    sites = np.arange(N * N).reshape(N, N)
    
    # Horizontal bonds (N rows, N-1 bonds per row)
    h_bonds = np.random.rand(N, N-1) < p
    
    # Vertical bonds (N-1 rows, N bonds per row)
    v_bonds = np.random.rand(N-1, N) < p
    
    # Union-Find for cluster identification
    parent = np.arange(N * N)
    
    def find(x):
        if parent[x] != x:
            parent[x] = find(parent[x])
        return parent[x]
    
    def union(x, y):
        px, py = find(x), find(y)
        if px != py:
            parent[px] = py
    
    # Connect horizontal bonds
    for i in range(N):
        for j in range(N-1):
            if h_bonds[i, j]:
                union(sites[i, j], sites[i, j+1])
    
    # Connect vertical bonds
    for i in range(N-1):
        for j in range(N):
            if v_bonds[i, j]:
                union(sites[i, j], sites[i+1, j])
    
    # Find largest cluster
    clusters = {}
    for site in range(N * N):
        root = find(site)
        clusters[root] = clusters.get(root, 0) + 1
    
    largest = max(clusters.values())
    S = largest / (N * N)
    
    return S
```

#### Step 3: Data Collection (1-2 hours runtime)

```python
# Data storage
results = {p: [] for p in p_values}

# Run simulations
for p in p_values:
    for trial in range(n_trials):
        S = bond_percolation_2d(N, p)
        results[p].append(S)
    
    # Progress
    if (p - p_values[0]) / (p_values[-1] - p_values[0]) % 0.1 < 0.01:
        print(f"Progress: p = {p:.3f}, <S> = {np.mean(results[p]):.3f}")

# Compute statistics
p_arr = []
S_mean = []
S_std = []

for p in p_values:
    p_arr.append(p)
    S_mean.append(np.mean(results[p]))
    S_std.append(np.std(results[p]))

p_arr = np.array(p_arr)
S_mean = np.array(S_mean)
S_std = np.array(S_std)
```

#### Step 4: Critical Point Estimation (15 min)

```python
# Method A: Find where S(p) = 0.5
idx_transition = np.argmin(np.abs(S_mean - 0.5))
p_c_estimate_1 = p_arr[idx_transition]

# Method B: Fit to scaling form S(p) ∝ (p - p_c)^β
def percolation_scaling(p, p_c, beta, A):
    """S(p) = A * (p - p_c)^β for p > p_c"""
    S = np.zeros_like(p)
    mask = p > p_c
    S[mask] = A * (p[mask] - p_c)**beta
    return S

# Fit above transition
fit_mask = (p_arr > 0.58) & (p_arr < 0.65)
popt, pcov = curve_fit(
    percolation_scaling,
    p_arr[fit_mask],
    S_mean[fit_mask],
    p0=[0.593, 0.139, 1.0],
    bounds=([0.58, 0.10, 0.5], [0.61, 0.20, 2.0])
)

p_c_estimate_2, beta_estimate, A = popt
p_c_error = np.sqrt(pcov[0, 0])
beta_error = np.sqrt(pcov[1, 1])

print(f"\nRESULTS:")
print(f"Method 1 (S=0.5): p_c = {p_c_estimate_1:.4f}")
print(f"Method 2 (fit):   p_c = {p_c_estimate_2:.4f} ± {p_c_error:.4f}")
print(f"Critical exponent: β = {beta_estimate:.4f} ± {beta_error:.4f}")
print(f"Expected: p_c = 0.5927, β = 0.1389")
```

#### Step 5: Visualization (10 min)

```python
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Plot 1: S(p) curve
ax = axes[0]
ax.errorbar(p_arr, S_mean, yerr=S_std, fmt='o', label='Simulation')
ax.axvline(0.5927, color='r', linestyle='--', label='Theory (0.5927)')
ax.axvline(0.600, color='orange', linestyle='--', label='Framework claim (0.600)')
ax.axhline(0.5, color='gray', linestyle=':')
ax.set_xlabel('Bond probability p')
ax.set_ylabel('Percolation strength S(p)')
ax.set_title('2D Square Lattice Bond Percolation')
ax.legend()
ax.grid(True, alpha=0.3)

# Plot 2: Log-log near transition
ax = axes[1]
mask = (p_arr > p_c_estimate_2) & (p_arr < 0.65)
ax.loglog(p_arr[mask] - p_c_estimate_2, S_mean[mask], 'o', label='Data')
ax.loglog(
    p_arr[mask] - p_c_estimate_2,
    A * (p_arr[mask] - p_c_estimate_2)**beta_estimate,
    'r-',
    label=f'Fit: β = {beta_estimate:.3f}'
)
ax.set_xlabel('p - p_c')
ax.set_ylabel('S(p)')
ax.set_title('Scaling: S(p) ∝ (p - p_c)^β')
ax.legend()
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('percolation_validation.png', dpi=300)
plt.show()
```

#### Step 6: Statistical Validation (10 min)

```python
# Check falsification criteria
print("\n=== FALSIFICATION CHECKS ===")

# Criterion 1: p_c in expected range
if 0.58 <= p_c_estimate_2 <= 0.60:
    print(f"✅ PASS: p_c = {p_c_estimate_2:.4f} in range [0.58, 0.60]")
else:
    print(f"❌ FAIL: p_c = {p_c_estimate_2:.4f} outside [0.58, 0.60]")

# Criterion 2: Transition observed
if np.max(S_mean) > 0.8 and np.min(S_mean) < 0.2:
    print(f"✅ PASS: Clear transition observed (min={np.min(S_mean):.3f}, max={np.max(S_mean):.3f})")
else:
    print(f"❌ FAIL: No clear transition")

# Criterion 3: Critical exponent
if 0.13 <= beta_estimate <= 0.15:
    print(f"✅ PASS: β = {beta_estimate:.4f} in universality class [0.13, 0.15]")
else:
    print(f"⚠️  WARNING: β = {beta_estimate:.4f} outside expected range")

# Criterion 4: Framework claim (μ_P = 0.600)
if abs(p_c_estimate_2 - 0.600) < 0.01:
    print(f"⚠️  NOTE: Framework claim μ_P=0.600 supported")
else:
    print(f"✅ CONFIRMED: Framework claim μ_P=0.600 FALSIFIED (p_c ≈ 0.593)")

# Compute confidence interval
confidence_95 = 1.96 * p_c_error
print(f"\n95% CI: p_c = {p_c_estimate_2:.4f} ± {confidence_95:.4f}")
print(f"Range: [{p_c_estimate_2 - confidence_95:.4f}, {p_c_estimate_2 + confidence_95:.4f}]")
```

---

### EXPECTED COMPUTATIONAL RESULTS

**Simulation Parameters:**
- Lattice size: N = 100
- Trials per p: n = 100
- Total simulations: 41 × 100 = 4,100
- Runtime: ~2 hours (Python, single core)

**Expected Output:**
```
p_c = 0.593 ± 0.003  (consistent with theory 0.5927)
β = 0.139 ± 0.01     (consistent with theory 5/36)
μ_P = 0.600 FALSIFIED (differs by >2σ)
```

---

## METHOD 2: PHYSICAL EXPERIMENT (RESISTOR NETWORK)

### Advantages:
- ✅ Physical validation (not just simulation)
- ✅ Tangible demonstration
- ✅ Educational value

### Disadvantages:
- ❌ Cost: $500-$2000
- ❌ Time: 20-40 hours
- ❌ Complexity: Moderate (electrical engineering)
- ❌ Precision: Lower than computational

---

### PHYSICAL PROCEDURE

#### Materials List:

**Electronics:**
- 10,000× 1kΩ resistors (100×100 array)
- 10,000× SPST switches (or relays)
- Microcontroller (Arduino Mega or Raspberry Pi)
- Relay driver boards (×100)
- Ohmmeter / multimeter (4-wire measurement)
- Power supply (5V, 10A)
- Breadboards or custom PCB

**Mechanical:**
- Mounting board (1m × 1m)
- Wiring (10km total, use ribbon cable)
- Connectors

**Total Cost:** $1,500-2,000  
**Assembly Time:** 30 hours  
**Measurement Time:** 10 hours

#### Setup:

```
1. Create 100×100 grid of nodes
2. Connect each adjacent pair with:
   [RESISTOR] -- [SWITCH] -- [RESISTOR]
3. Control switches via microcontroller
4. Measure resistance across lattice
```

#### Measurement Protocol:

```python
# Pseudocode for Arduino/Python control
for p in [0.50, 0.52, ..., 0.70]:
    for trial in range(100):
        # Randomly close fraction p of switches
        switch_states = (random() < p for all switches)
        set_switches(switch_states)
        
        # Measure resistance
        R = measure_4wire_resistance(left_edge, right_edge)
        
        # Determine if percolating
        percolating = (R < R_threshold)  # e.g., R < 10kΩ
        
        record(p, trial, R, percolating)
    
    # Compute percolation probability
    prob_percolate[p] = mean(percolating for trials at p)

# Find p_c where prob = 0.5
p_c_physical = interpolate(prob_percolate, target=0.5)
```

#### Expected Physical Results:

```
p_c_physical = 0.59 ± 0.02  (larger error than simulation)
Transition width: Δp ≈ 0.05 (finite-size effects)
```

#### Challenges:

1. **Contact Resistance:** Can dominate signal
   - Mitigation: 4-wire measurement, calibration

2. **Finite Size Effects:** N=100 not infinite
   - Mitigation: Finite-size scaling analysis

3. **Switch Reliability:** Mechanical switches fail
   - Mitigation: Solid-state relays, redundancy

4. **Cost:** $2000 for single measurement
   - Mitigation: Start with N=20 prototype ($100)

---

## METHOD 3: HYBRID (COMPUTATIONAL + SMALL PHYSICAL)

**Recommendation:** Validate computationally first, then build small (20×20) physical demo.

**Benefits:**
- Rigorous: Computational precision
- Tangible: Physical demonstration
- Affordable: $100-200 for demo
- Educational: Best of both worlds

---

## DATA ANALYSIS

### Statistical Tests:

1. **Goodness of Fit:**
   ```python
   # Chi-square test for scaling
   chi2, p_value = chisquare(S_observed, S_expected)
   # Accept if p_value > 0.05
   ```

2. **Confidence Intervals:**
   ```python
   # Bootstrap resampling
   bootstrap_pc = []
   for i in range(1000):
       resampled_data = resample(results)
       pc_i = estimate_pc(resampled_data)
       bootstrap_pc.append(pc_i)
   
   CI_95 = np.percentile(bootstrap_pc, [2.5, 97.5])
   ```

3. **Comparison to Theory:**
   ```python
   # t-test: Is p_c_measured consistent with p_c_theory = 0.5927?
   t_stat = (p_c_measured - 0.5927) / (std_error)
   p_value = t_test(t_stat, df=n_trials-1)
   # Accept if p_value > 0.05
   ```

---

## FALSIFICATION OUTCOMES

### Case 1: p_c = 0.593 ± 0.003
**Result:** ✅ Consistent with theory  
**Interpretation:** Percolation model validated  
**Framework:** μ_P = 0.600 claim FALSIFIED (confirmed)

### Case 2: p_c = 0.600 ± 0.003
**Result:** ⚠️ Disagrees with established theory  
**Interpretation:** Either experimental error OR new physics  
**Action:** Repeat with larger N, check implementation

### Case 3: No transition in [0.5, 0.7]
**Result:** ❌ Percolation model fails  
**Interpretation:** Fundamental issue with lattice or algorithm  
**Action:** Debug code, verify lattice structure

### Case 4: p_c outside [0.58, 0.60]
**Result:** ❌ Both theory and framework wrong  
**Interpretation:** Wrong model (not 2D square bond percolation)  
**Action:** Identify correct model

---

## REPORTING

### Minimal Report (2 pages):

**Title:** Computational Validation of Percolation Threshold for 2D Square Lattice

**Abstract:** We simulated bond percolation on 100×100 square lattice with 100 trials per bond probability. Results: p_c = 0.593 ± 0.003, β = 0.139 ± 0.01, consistent with theoretical predictions (p_c = 0.5927, β = 5/36). The framework claim μ_P = 0.600 is falsified at >2σ significance.

**Methods:** [Algorithm description]

**Results:** [Figure 1: S(p), Figure 2: Scaling]

**Discussion:** Percolation threshold model-specific, not universal 0.600.

**Conclusion:** Computational validation successful. Recommends correcting framework μ_P → p_c.

---

### Full Report (10 pages):

Include:
1. Extended theoretical background
2. Complete algorithm listing
3. Error analysis (finite-size scaling)
4. Comparison to literature (Ziff, Newman-Ziff)
5. Discussion of universality classes
6. Physical interpretation for framework
7. Recommendations for other models (3D, site percolation, etc.)

---

## TIMELINE

### Computational Path:

| Task | Duration |
|------|----------|
| Code implementation | 1 hour |
| Simulation execution | 2 hours |
| Data analysis | 1 hour |
| Visualization | 30 min |
| Report writing | 2 hours |
| **TOTAL** | **6.5 hours** |

### Physical Path:

| Task | Duration |
|------|----------|
| Design circuit | 4 hours |
| Order parts | 3 days |
| Assembly | 30 hours |
| Testing/debugging | 10 hours |
| Measurements | 10 hours |
| Analysis | 4 hours |
| Report | 4 hours |
| **TOTAL** | **62 hours + wait time** |

**Recommendation:** Execute computational first (6.5 hours), defer physical to later if needed.

---

## SUCCESS CRITERIA

**Experiment Successful If:**
1. ✅ Clear transition observed (S: 0 → 1)
2. ✅ p_c in range [0.58, 0.60]
3. ✅ β in range [0.13, 0.15]
4. ✅ Reproducible (same seed → same results)
5. ✅ Statistical significance (p < 0.05)

**Framework Correction Confirmed If:**
6. ✅ p_c ≠ 0.600 (differs by >2σ)
7. ✅ p_c ≈ 0.593 (matches percolation theory)

---

## REFERENCES

1. Stauffer, D. & Aharony, A. (1994). *Introduction to Percolation Theory*. Taylor & Francis.

2. Newman, M. E. J. & Ziff, R. M. (2000). "Efficient Monte Carlo algorithm and high-precision results for percolation". *Physical Review Letters*, 85(19), 4104.

3. Ziff, R. M. (1992). "Spanning probability in 2D percolation". *Physical Review Letters*, 69(18), 2670-2673.

4. Saberi, A. A. (2015). "Recent advances in percolation theory and its applications". *Physics Reports*, 578, 1-32.

5. Grimmett, G. (1999). *Percolation*. Springer.

---

**PROTOCOL STATUS:** READY FOR EXECUTION  
**RECOMMENDATION:** Begin with computational validation (Method 1)  
**EXPECTED OUTCOME:** Confirmation that μ_P = 0.600 is falsified, p_c ≈ 0.593

**NEXT PROTOCOL:** Kuramoto Synchronization (Theorem SR6, phase transitions)

